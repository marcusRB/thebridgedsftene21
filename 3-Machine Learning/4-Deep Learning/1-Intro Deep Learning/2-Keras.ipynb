{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap = plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# reshape(-1, 28*28)\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001CC8BDC5430>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1cc8bdc5700>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1cc8bdc5430>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1cc8be582e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1cc8be038e0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[1])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03703096,  0.01505364,  0.02422893, ...,  0.06605117,\n",
       "        -0.05832141, -0.05438862],\n",
       "       [-0.01809431,  0.02408525, -0.04081807, ...,  0.03063899,\n",
       "        -0.0423815 ,  0.02567116],\n",
       "       [ 0.07131575,  0.07258727, -0.01281995, ...,  0.00667768,\n",
       "        -0.05181305,  0.01195982],\n",
       "       ...,\n",
       "       [ 0.02387783, -0.04138074, -0.03394711, ..., -0.07433589,\n",
       "        -0.03203893,  0.0415445 ],\n",
       "       [ 0.03255668,  0.06576119,  0.0445011 , ..., -0.04263898,\n",
       "        -0.06218193, -0.04230883],\n",
       "       [-0.00788664, -0.06935962, -0.03726583, ...,  0.06111574,\n",
       "         0.0356935 ,  0.0426139 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(optimizer=\"sgd\",\n",
    "             loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics = [\"accuracy\"]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 1.3148 - accuracy: 0.6669 - val_loss: 0.3879 - val_accuracy: 0.8993\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3889 - accuracy: 0.8928 - val_loss: 0.3004 - val_accuracy: 0.9154\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3181 - accuracy: 0.9096 - val_loss: 0.2654 - val_accuracy: 0.9255\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2819 - accuracy: 0.9206 - val_loss: 0.2433 - val_accuracy: 0.9310\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2560 - accuracy: 0.9272 - val_loss: 0.2212 - val_accuracy: 0.9380\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2317 - accuracy: 0.9346 - val_loss: 0.2052 - val_accuracy: 0.9428\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2184 - accuracy: 0.9392 - val_loss: 0.1941 - val_accuracy: 0.9450\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1938 - accuracy: 0.9443 - val_loss: 0.1831 - val_accuracy: 0.9499\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1881 - accuracy: 0.9451 - val_loss: 0.1742 - val_accuracy: 0.9527\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1737 - accuracy: 0.9509 - val_loss: 0.1673 - val_accuracy: 0.9533\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1648 - accuracy: 0.9512 - val_loss: 0.1574 - val_accuracy: 0.9572\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1548 - accuracy: 0.9559 - val_loss: 0.1506 - val_accuracy: 0.9581\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1442 - accuracy: 0.9578 - val_loss: 0.1453 - val_accuracy: 0.9607\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1384 - accuracy: 0.9610 - val_loss: 0.1425 - val_accuracy: 0.9608\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1323 - accuracy: 0.9627 - val_loss: 0.1359 - val_accuracy: 0.9628\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 15,\n",
    "    validation_data = (X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1233 - accuracy: 0.9649 - val_loss: 0.1278 - val_accuracy: 0.9645\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1173 - accuracy: 0.9671 - val_loss: 0.1273 - val_accuracy: 0.9654\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1122 - accuracy: 0.9687 - val_loss: 0.1222 - val_accuracy: 0.9656\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1071 - accuracy: 0.9696 - val_loss: 0.1181 - val_accuracy: 0.9679\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1025 - accuracy: 0.9716 - val_loss: 0.1156 - val_accuracy: 0.9672\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0983 - accuracy: 0.9729 - val_loss: 0.1129 - val_accuracy: 0.9684\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0942 - accuracy: 0.9739 - val_loss: 0.1088 - val_accuracy: 0.9693\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0906 - accuracy: 0.9747 - val_loss: 0.1072 - val_accuracy: 0.9696\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0869 - accuracy: 0.9763 - val_loss: 0.1056 - val_accuracy: 0.9705\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.9772 - val_loss: 0.1032 - val_accuracy: 0.9703\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9784 - val_loss: 0.1008 - val_accuracy: 0.9710\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0773 - accuracy: 0.9788 - val_loss: 0.0987 - val_accuracy: 0.9716\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0744 - accuracy: 0.9798 - val_loss: 0.1002 - val_accuracy: 0.9719\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0717 - accuracy: 0.9808 - val_loss: 0.0974 - val_accuracy: 0.9720\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0692 - accuracy: 0.9815 - val_loss: 0.0957 - val_accuracy: 0.9729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cc8cfe1b80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 15,\n",
    "    validation_data = (X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 15, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.840785026550293,\n",
       "  0.37122276425361633,\n",
       "  0.3089354932308197,\n",
       "  0.27388930320739746,\n",
       "  0.24819378554821014,\n",
       "  0.22732754051685333,\n",
       "  0.2102602869272232,\n",
       "  0.19529199600219727,\n",
       "  0.1825505644083023,\n",
       "  0.17119699716567993,\n",
       "  0.1612524539232254,\n",
       "  0.1520371437072754,\n",
       "  0.14422869682312012,\n",
       "  0.13639794290065765,\n",
       "  0.12947070598602295],\n",
       " 'accuracy': [0.8001999855041504,\n",
       "  0.8969600200653076,\n",
       "  0.9124600291252136,\n",
       "  0.9223799705505371,\n",
       "  0.9295399785041809,\n",
       "  0.9355800151824951,\n",
       "  0.940500020980835,\n",
       "  0.9435999989509583,\n",
       "  0.9470999836921692,\n",
       "  0.9516000151634216,\n",
       "  0.953499972820282,\n",
       "  0.9562000036239624,\n",
       "  0.9581400156021118,\n",
       "  0.9614400267601013,\n",
       "  0.9632400274276733],\n",
       " 'val_loss': [0.3878802955150604,\n",
       "  0.3004181385040283,\n",
       "  0.26535382866859436,\n",
       "  0.24334976077079773,\n",
       "  0.2212330847978592,\n",
       "  0.20515859127044678,\n",
       "  0.1941392421722412,\n",
       "  0.1831369400024414,\n",
       "  0.17421618103981018,\n",
       "  0.16731709241867065,\n",
       "  0.15740913152694702,\n",
       "  0.1505732238292694,\n",
       "  0.1452787071466446,\n",
       "  0.1424761414527893,\n",
       "  0.13594983518123627],\n",
       " 'val_accuracy': [0.8992999792098999,\n",
       "  0.9154000282287598,\n",
       "  0.9254999756813049,\n",
       "  0.9309999942779541,\n",
       "  0.9380000233650208,\n",
       "  0.942799985408783,\n",
       "  0.9449999928474426,\n",
       "  0.9498999714851379,\n",
       "  0.9527000188827515,\n",
       "  0.9532999992370605,\n",
       "  0.9571999907493591,\n",
       "  0.9581000208854675,\n",
       "  0.9606999754905701,\n",
       "  0.9607999920845032,\n",
       "  0.9628000259399414]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.840785026550293,\n",
       "  0.37122276425361633,\n",
       "  0.3089354932308197,\n",
       "  0.27388930320739746,\n",
       "  0.24819378554821014,\n",
       "  0.22732754051685333,\n",
       "  0.2102602869272232,\n",
       "  0.19529199600219727,\n",
       "  0.1825505644083023,\n",
       "  0.17119699716567993,\n",
       "  0.1612524539232254,\n",
       "  0.1520371437072754,\n",
       "  0.14422869682312012,\n",
       "  0.13639794290065765,\n",
       "  0.12947070598602295],\n",
       " 'accuracy': [0.8001999855041504,\n",
       "  0.8969600200653076,\n",
       "  0.9124600291252136,\n",
       "  0.9223799705505371,\n",
       "  0.9295399785041809,\n",
       "  0.9355800151824951,\n",
       "  0.940500020980835,\n",
       "  0.9435999989509583,\n",
       "  0.9470999836921692,\n",
       "  0.9516000151634216,\n",
       "  0.953499972820282,\n",
       "  0.9562000036239624,\n",
       "  0.9581400156021118,\n",
       "  0.9614400267601013,\n",
       "  0.9632400274276733],\n",
       " 'val_loss': [0.3878802955150604,\n",
       "  0.3004181385040283,\n",
       "  0.26535382866859436,\n",
       "  0.24334976077079773,\n",
       "  0.2212330847978592,\n",
       "  0.20515859127044678,\n",
       "  0.1941392421722412,\n",
       "  0.1831369400024414,\n",
       "  0.17421618103981018,\n",
       "  0.16731709241867065,\n",
       "  0.15740913152694702,\n",
       "  0.1505732238292694,\n",
       "  0.1452787071466446,\n",
       "  0.1424761414527893,\n",
       "  0.13594983518123627],\n",
       " 'val_accuracy': [0.8992999792098999,\n",
       "  0.9154000282287598,\n",
       "  0.9254999756813049,\n",
       "  0.9309999942779541,\n",
       "  0.9380000233650208,\n",
       "  0.942799985408783,\n",
       "  0.9449999928474426,\n",
       "  0.9498999714851379,\n",
       "  0.9527000188827515,\n",
       "  0.9532999992370605,\n",
       "  0.9571999907493591,\n",
       "  0.9581000208854675,\n",
       "  0.9606999754905701,\n",
       "  0.9607999920845032,\n",
       "  0.9628000259399414]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9714\n",
      "test loss, test acc: [0.09450620412826538, 0.9714000225067139]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.001, 0.   , 0.   , 0.   , 0.998, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7520 - val_loss: 0.5975\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(input_shape = X_train.shape[1:],\n",
    "                      units = 30,\n",
    "                      activation=\"relu\"),\n",
    "    \n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "         y_train,\n",
    "         epochs=1,\n",
    "         validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 663us/step - loss: 0.3259\n",
      "0.3259105980396271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.7329999],\n",
       "       [1.1171376],\n",
       "       [5.0768604]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)\n",
    "\n",
    "model.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.38   , 0.773  , 5.00001])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3150\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 779us/step - loss: 0.3174\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.3131\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.3134\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 819us/step - loss: 0.3144\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3133\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3131\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3127\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.3168\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.3138\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 690us/step - loss: 0.3123\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.3213\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.3145\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.3151\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.3204\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.3145\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 708us/step - loss: 0.3251\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3261\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3124\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3125\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    callbacks = [checkpoint_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.3211\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.3300\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.3210\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3153 - val_loss: 0.3199\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3143 - val_loss: 0.3311\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3189\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3135 - val_loss: 0.3334\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3259\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3319\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 3,\n",
    "                                                 restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    callbacks = [checkpoint_cb, early_stopping_cb],\n",
    "    validation_data = (X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard\n",
    "Keras tiene implementado un dashboard para monitorizar las ejecuciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crea este directorio\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Guarda una carpeta nueva con la fecha de la ejecucion\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3129 - val_loss: 0.3223\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.3185\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.3205\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.3272\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3234\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.3172\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3285\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.3239\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3208\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3219\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3239\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.3193\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.3210\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3238\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3161\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3107 - val_loss: 0.3171\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3128 - val_loss: 0.3212\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3288\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3154\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3116 - val_loss: 0.3164\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3189\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3184\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3263\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3224\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3186\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3193\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3096 - val_loss: 0.3176\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3177\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3200\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3099 - val_loss: 0.3200\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3109 - val_loss: 0.3143\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3093 - val_loss: 0.3176\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3199\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3116\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.3188\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3255\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3204\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.3168\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3215\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3215\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3145\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3183\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.3230\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.3224\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3201\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.3172\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3369\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3183\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.3190\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.3132\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Para lanzarlo desde el jupyter notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "Para lanzarlo desde el terminal, hay que estar en la carpeta de los logs\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
